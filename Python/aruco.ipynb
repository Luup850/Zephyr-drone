{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 is not a camera\n",
      "Device 1 is a camera\n",
      "Device 2 is a camera\n",
      "Device 3 is not a camera\n",
      "Device 4 is not a camera\n",
      "Device 5 is not a camera\n",
      "Device 6 is not a camera\n",
      "Device 7 is not a camera\n",
      "Device 8 is not a camera\n",
      "Device 9 is not a camera\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "# Print video capture devices\n",
    "def print_video_devices():\n",
    "    for i in range(10):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        if cap.read()[0]:\n",
    "            print(f\"Device {i} is a camera\")\n",
    "        else:\n",
    "            print(f\"Device {i} is not a camera\")\n",
    "        cap.release()\n",
    "\n",
    "print_video_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate aruco markers\n",
    "def generate_aruco_markers():\n",
    "    # Dictionary of 250 markers\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "\n",
    "    # Create an image from the dictionary\n",
    "    for i in range(250):\n",
    "        img = aruco.drawMarker(aruco_dict, i, 700)\n",
    "\n",
    "        # Get current dir path\n",
    "        path = os.getcwd()\n",
    "\n",
    "        cv2.imwrite(path + \"/markers/\" + str(i) + \".jpg\", img)\n",
    "\n",
    "\n",
    "# Detect aruco markers\n",
    "def detect_aruco_markers(aruco_dict, frame):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect aruco markers\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Draw detected markers\n",
    "    frame = aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "    return frame, corners, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking picture 0\n",
      "Taking picture 1\n",
      "Taking picture 2\n",
      "Taking picture 3\n",
      "Taking picture 4\n",
      "Taking picture 5\n",
      "Taking picture 6\n",
      "Taking picture 7\n",
      "Taking picture 8\n",
      "Taking picture 9\n",
      "Taking picture 10\n",
      "Taking picture 11\n",
      "Taking picture 12\n",
      "Taking picture 13\n",
      "Taking picture 14\n",
      "Taking picture 15\n",
      "Taking picture 16\n",
      "Taking picture 17\n",
      "Taking picture 18\n",
      "Taking picture 19\n"
     ]
    }
   ],
   "source": [
    "# Take a picture each second\n",
    "\n",
    "#cam = cv2.VideoCapture(1)\n",
    "#for i in range(20):\n",
    "#\n",
    "#    ret, frame = cam.read()\n",
    "#\n",
    "#    print(f'Taking picture {i}')\n",
    "#        \n",
    "#    cv2.imwrite(\"C:\\\\Users\\\\Marcus\\\\Documents\\\\GitHub\\\\Zephyr-drone\\\\Python\\\\calibration\\\\\" + str(i) + \".jpg\", frame)\n",
    "#    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calibrate camera\n",
    "def calibrate_camera():\n",
    "    # Get current dir path\n",
    "    path = os.getcwd()\n",
    "\n",
    "    # Termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6 * 7, 3), np.float32)\n",
    "\n",
    "    # Create an array with coordinates of the corners\n",
    "    objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane\n",
    "\n",
    "    # Get images from the calibration folder\n",
    "    images = [f for f in os.listdir(path + \"/calibration\") if f.endswith('.jpg')]\n",
    "\n",
    "    for fname in images:\n",
    "        # Read image\n",
    "        img = cv2.imread(path + \"/calibration/\" + fname)\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (7, 6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            # Refine the corners\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "            # Add image points\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (7, 6), corners2, ret)\n",
    "\n",
    "    # Calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "# Undistort image\n",
    "def undistort_image(img, mtx, dist):\n",
    "    # Undistort image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    return dst\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera()\n",
    "\n",
    "dst = cv2.imread(\"C:\\\\Users\\\\Marcus\\\\Documents\\\\GitHub\\\\Zephyr-drone\\\\Python\\\\calibration\\\\0.jpg\")\n",
    "\n",
    "img = undistort_image(dst, mtx, dist)\n",
    "\n",
    "# Set img side by side with undistorted image\n",
    "img = np.hstack((img, dst))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12692/3959487117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorners\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_aruco_markers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDICT_6X6_250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Camera\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12692/277410458.py\u001b[0m in \u001b[0;36mdetect_aruco_markers\u001b[1;34m(aruco_dict, frame)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_aruco_markers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Convert frame to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Detect aruco markers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "# Show camera feed\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    img,corners,ids = detect_aruco_markers(aruco.Dictionary_get(aruco.DICT_6X6_250), frame)\n",
    "    cv2.imshow(\"Camera\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
