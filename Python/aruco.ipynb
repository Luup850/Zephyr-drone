{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "# Print video capture devices\n",
    "#def print_video_devices():\n",
    "#    for i in range(10):\n",
    "#        cap = cv2.VideoCapture(i)\n",
    "#        if cap.read()[0]:\n",
    "#            print(f\"Device {i} is a camera\")\n",
    "#        else:\n",
    "#            print(f\"Device {i} is not a camera\")\n",
    "#        cap.release()\n",
    "#\n",
    "#print_video_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate aruco markers\n",
    "def generate_aruco_markers():\n",
    "    # Dictionary of 250 markers\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "\n",
    "    # Create an image from the dictionary\n",
    "    for i in range(250):\n",
    "        img = aruco.drawMarker(aruco_dict, i, 700)\n",
    "\n",
    "        # Get current dir path\n",
    "        path = os.getcwd()\n",
    "\n",
    "        cv2.imwrite(path + \"/markers/\" + str(i) + \".jpg\", img)\n",
    "\n",
    "\n",
    "# Detect aruco markers\n",
    "def detect_aruco_markers(aruco_dict, frame):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect aruco markers\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Draw detected markers\n",
    "    frame = aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "    return frame, corners, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a picture each second\n",
    "\n",
    "#cam = cv2.VideoCapture(1)\n",
    "#for i in range(20):\n",
    "#\n",
    "#    ret, frame = cam.read()\n",
    "#\n",
    "#    print(f'Taking picture {i}')\n",
    "#        \n",
    "#    cv2.imwrite(\"C:\\\\Users\\\\Marcus\\\\Documents\\\\GitHub\\\\Zephyr-drone\\\\Python\\\\calibration\\\\\" + str(i) + \".jpg\", frame)\n",
    "#    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate camera\n",
    "def calibrate_camera():\n",
    "    # Get current dir path\n",
    "    path = os.getcwd()\n",
    "\n",
    "    # Termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6 * 7, 3), np.float32)\n",
    "\n",
    "    # Create an array with coordinates of the corners\n",
    "    objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane\n",
    "\n",
    "    # Get images from the calibration folder\n",
    "    images = [f for f in os.listdir(path + \"/calibration\") if f.endswith('.jpg')]\n",
    "\n",
    "    for fname in images:\n",
    "        # Read image\n",
    "        img = cv2.imread(path + \"/calibration/\" + fname)\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (7, 6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            # Refine the corners\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "            # Add image points\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (7, 6), corners2, ret)\n",
    "\n",
    "    # Calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "# Undistort image\n",
    "def undistort_image(img, mtx, dist):\n",
    "    # Undistort image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    return dst\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera()\n",
    "\n",
    "dst = cv2.imread(\"C:\\\\Users\\\\Marcus\\\\Documents\\\\GitHub\\\\Zephyr-drone\\\\Python\\\\calibration\\\\19.jpg\")\n",
    "\n",
    "#img = undistort_image(dst, mtx, dist)\n",
    "\n",
    "# Set img side by side with undistorted image\n",
    "#img = np.hstack((img, dst))\n",
    "#cv2.imshow('img', img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate pose from aruco marker\n",
    "def estimate_pose_from_aruco_marker(frame, mtx, dist):\n",
    "\n",
    "    # Get marker length\n",
    "    markerLength = 0.05\n",
    "    mtx = np.array(mtx)\n",
    "\n",
    "    # Get aruco dictionary\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "\n",
    "    # Get camera parameters\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "\n",
    "    # Detect aruco markers\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Estimate pose\n",
    "    print()\n",
    "    rvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners, markerLength, mtx, dist)\n",
    "\n",
    "    # draw axis for the aruco markers\n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            frame = aruco.drawAxis(frame, mtx, dist, rvec[i], tvec[i], 0.01)\n",
    "\n",
    "    # Get x, y, z\n",
    "    if tvec is not None:\n",
    "        x = tvec[0][0][0]\n",
    "        y = tvec[0][0][1]\n",
    "        z = tvec[0][0][2]\n",
    "        return frame, rvec, tvec, x, y, z\n",
    "    else:\n",
    "        return frame, rvec, tvec, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Show camera feed\n",
    "while False:\n",
    "    ret, frame = cam.read()\n",
    "#    img,corners,ids = detect_aruco_markers(aruco.Dictionary_get(aruco.DICT_6X6_250), frame)\n",
    "    img,rvec,tvec,x,y,z = estimate_pose_from_aruco_marker(frame, mtx, dist)\n",
    "    # Add x y z coords to bottom left corner with a small font\n",
    "    cv2.putText(img, \"x: \" + str(x), (10, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(img, \"y: \" + str(y), (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(img, \"z: \" + str(z), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.imshow(\"Camera\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
